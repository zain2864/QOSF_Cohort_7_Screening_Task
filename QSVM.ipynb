{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "This file contains my solution (Zain Mughal) to the Screening Task #3 of Cohort 7 of the QOSF Mentorship Program \n",
        "\n",
        "The problem statement is mentioned below, and the references of how I am solving the problem. I will be implementing the task using Python and Qiskit. \n",
        "\n",
        "#Task 3: QSVM\n",
        "\n",
        "Generate a Quantum Support Vector Machine (QSVM) using the iris dataset and try to propose a kernel from a parametric quantum circuit to classify the three classes(setosa, versicolor, virginica) using the one-vs-all format, the kernel only works as binary classification. Identify the proposal with the lowest number of qubits and depth to obtain higher accuracy. You can use the UU† format or using the Swap-Test.\n",
        "\n",
        "<br>\n",
        "\n",
        "#Background and References\n",
        "The task is asking to use the one-vs-all format, which is a strategy used in multi-class classification problems to transform a problem with multiple classes into a set of binary classification problems. For each class, a binary classifier is trained to distinguish samples belonging to that class from samples not belonging to that class. This results in a set of binary classifiers, one for each class.\n",
        "\n",
        "<br>\n",
        "\n",
        "In the task it says to use UU† format or using the Swap-Test:\n",
        "  1. The UU† format is a way to represent a unitary matrix using two other unitary matrices, U and U†. Specifically, any unitary matrix can be written in the form UU†e^{iθ}, where θ is a global phase. This format is useful in quantum algorithms because it allows a unitary matrix to be implemented using only two unitary gates, U and U†, which can be easier to implement than a full unitary matrix.\n",
        "  2. In a quantum support vector machine, the Swap-Test can be used to compute the inner product between two quantum states, which is needed to evaluate the quantum kernel function used in the algorithm. Specifically, given two quantum states encoded as quantum circuits, the Swap-Test circuit can be used to measure the overlap between the two states, which can then be used to evaluate the quantum kernel function.\n",
        "\n",
        "<br>\n",
        "\n",
        "I have decided to use the SWAP Test Implementation.\n",
        "\n",
        "We are also tasked with finding a proposal with the lowest number of qubits and depth to obtain higher accuracy. My plan is to first implement the QSVM in Qiskit, using their QSVC Class and the one-vs-all format, with the Standard Swap Gate. After, I use GridSearchCV to tune the hyperparameters for a higher accuracy.\n",
        "Then, after doing some research, I found that the Standard Swap Gate Kernel implemented is inefficient, since it requires 3 qubits and a depth=7, and that we can make modifications, using CX-gates to act as the \"swap\", which reduces the number of qubits. \n",
        "\n",
        "\n",
        "References: \n",
        "  1. https://en.wikipedia.org/wiki/Swap_test (Given from Problem Statement)\n",
        "  2. https://learn.qiskit.org/summer-school/2021/lab3-introduction-quantum-kernels-support-vector-machines (Qiskit Lab)\n",
        "  3. https://arxiv.org/pdf/1804.11326.pdf  (Supervised learning with quantum enhanced feature spaces, Pages 18-19)"
      ],
      "metadata": {
        "id": "qTNSseCVMzXa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SERsCyl78zMD"
      },
      "outputs": [],
      "source": [
        "!pip install qiskit\n",
        "!pip install qiskit[machine-learning]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Import the Libraries\n",
        "import numpy as np\n",
        "from sklearn.datasets import load_iris\n",
        "from qiskit import QuantumCircuit, QuantumRegister, ClassicalRegister, execute, Aer\n",
        "from qiskit_machine_learning.algorithms.classifiers import QSVC\n",
        "from qiskit_machine_learning.kernels import QuantumKernel\n",
        "from qiskit.circuit.library import HGate, CXGate, CSwapGate\n",
        "from qiskit.circuit.library import ZFeatureMap \n",
        "from qiskit import Aer\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\"\"\"\n",
        "In this assignment, I had done some experimentation of which feature map to use. \n",
        "I originally started with the ZZFeatureMap, which is the traditional choice for implementing QSVC, \n",
        "however, I decided to use the ZFeatureMap instead. The ZZFeatureMap is better at dealing with \n",
        "non-linear data, however it took 2x the time to run my implementation, achieving accuracies of 70%-85%, after fine tuning. \n",
        "Similar using the PauliFeatureMap, it was about 1.5x longer, and yielded lower results from 40%-73%, after fine tuning. \n",
        "Thus I decided to use ZFeatureMap. \n",
        "\"\"\"\n",
        "#from qiskit.circuit.library import PauliFeatureMap\n",
        "#from qiskit.circuit.library import ZZFeatureMap"
      ],
      "metadata": {
        "id": "n8X38RtZ81ZF"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "We need to process the data, by loading the Iris Dataset, and splitting the dataset into training and testing sets. \n",
        "Here, I decided to use the standard 80% of the dataset for training, and 20% for the testing set. \n",
        "\"\"\"\n",
        "\n",
        "# Load the iris dataset\n",
        "data = load_iris()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "70unlAbe-FBT"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Define the quantum kernel, which will be the SWAP Test Implementation.\n",
        "Since there are three qubits needed for the standard Swap Test, this implementation\n",
        "has a circuit depth of 7.\n",
        "\n",
        "\"\"\"\n",
        "num_qubits = 3\n",
        "def swap_test_kernel(qc, q, theta):\n",
        "    qc.h(q[0])\n",
        "    qc.h(q[1])\n",
        "    qc.h(q[2])\n",
        "    qc.cswap(q[0], q[1], q[2])\n",
        "    qc.h(q[0])\n",
        "    qc.h(q[1])\n",
        "    qc.measure_all()"
      ],
      "metadata": {
        "id": "9B2BHh95qz68"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "theta = np.random.uniform(0, 2*np.pi, num_qubits) \n",
        "\n",
        "\"\"\"\n",
        "Here I tested using different FeatureMaps and also varied their batch sizes. \n",
        "Using the different feature maps, changing batch sizes, etc., I was getting accuracies \n",
        "from a range of 3.6%-85%. I am including it to show how these feature maps can be implemented, \n",
        "incase one would want to test them out. \n",
        "\n",
        "\"\"\"\n",
        "# feature_map = PauliFeatureMap(feature_dimension=2, entanglement='linear')\n",
        "# quantum_instance = Aer.get_backend('qasm_simulator')\n",
        "# kernel = QuantumKernel(feature_map=feature_map, enforce_psd=True, batch_size=100, \n",
        "#                        quantum_instance=quantum_instance, training_parameters=None, \n",
        "#                        evaluate_duplicates='off_diagonal')\n",
        "\n",
        "# feature_map = ZZFeatureMap(feature_dimension=2, reps=2)\n",
        "# quantum_instance = Aer.get_backend('qasm_simulator')\n",
        "# kernel = QuantumKernel(feature_map=feature_map, enforce_psd=True, batch_size=40, \n",
        "#                        quantum_instance=quantum_instance, training_parameters=None, \n",
        "#                        evaluate_duplicates='off_diagonal')\n",
        "\n",
        "\n",
        "feature_map = ZFeatureMap(feature_dimension=2, reps=2)\n",
        "quantum_instance = Aer.get_backend('qasm_simulator')\n",
        "kernel = QuantumKernel(feature_map=feature_map, enforce_psd=True, batch_size=40, \n",
        "                       quantum_instance=quantum_instance, training_parameters=None, \n",
        "                       evaluate_duplicates='off_diagonal')\n",
        "\n"
      ],
      "metadata": {
        "id": "cWigmkO-PldD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "The original iris dataset has three classes of flowers: setosa, versicolor, and virginica. We want to train a QSVM to classify each flower into one of these three classes. \n",
        "However, the QSVC can only solve binary classification problems, where each sample is classified into one of two classes. To solve a multi-class classification problem using a QSVC, \n",
        "we need to convert it into several binary classification problems. Essentially being a QSVM. \n",
        "\n",
        "The one-vs-all format is one way to convert a multi-class classification problem into several binary classification problems. \n",
        "In this format, we train a QSVM for each class, where the samples of the target class are labeled as 1, and the samples of all other classes are labeled as 0. \n",
        "This way, each QSVM learns to distinguish the samples of one class from all other classes.\n",
        "\"\"\"\n",
        "\n",
        "# Train the QSVM using the one-vs-all approach\n",
        "qsvms = []\n",
        "for i in range(len(np.unique(y_train))):\n",
        "\n",
        "    # Preparing binary labels for the current class\n",
        "    y_train_binary = np.zeros(len(y_train))\n",
        "    y_train_binary[y_train == i] = 1\n",
        "    if np.sum(y_train_binary) == 0:\n",
        "        continue  # Skip if there are no samples for the current class\n",
        "\n",
        "    # Train the QSVM for the current class\n",
        "    qc = QuantumCircuit(num_qubits)\n",
        "    swap_test_kernel(qc, [0,1,2], theta)\n",
        "    qsvc = QSVC(quantum_kernel=kernel)\n",
        "    qsvc.fit(X_train, y_train_binary)\n",
        "    \n",
        "    qsvms.append(qsvc)\n",
        "   # print(f\"QSVC for class {i}: {qsvc}\")  # Print QSVC classifier for each class, to make sure the implementation is correct \n",
        "\n"
      ],
      "metadata": {
        "id": "shiN2dtkyLlO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the QSVM\n",
        "y_pred = np.zeros((len(X_test), len(np.unique(y_train)))) #len(np.unique(y_train)) should equal 2, since we have converted to binary classification problem \n",
        "for i in range(len(X_test)):\n",
        "    for j in range(len(np.unique(y_train))):\n",
        "        qc = QuantumCircuit(num_qubits)\n",
        "        swap_test_kernel(qc, [0,1,2], theta)\n",
        "        kernel.quantum_circuit = qc\n",
        "        y_pred[i, j] = qsvms[j].predict(X_test[i:i+1,:])\n",
        "\n",
        "y_pred = np.argmax(y_pred, axis=1)\n",
        "\n",
        "# Evaluate the accuracy of the QSVM\n",
        "accuracy = sum([y_test[i]==y_pred[i] for i in range(len(y_test))])/len(y_test)\n",
        "print('Accuracy:', accuracy)"
      ],
      "metadata": {
        "id": "7wpcauucyPUi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>\n",
        "<br>\n",
        "\n",
        "Before optimizing the number of qubits and depth, I want to tune the hyperparamaters to find a better accuracy. At the moment, the model was achieving a accuracy of 36%, which is very low. And so, I decided to make use of GridSearchCV from the sklearn.model_selection module. GridSearchCV is a technique for finding the optimal parameter values from a given set of parameters in a grid. It does this by trying different combination of all the specified hyperparameters and their values and calculates the performance for each combination and selects the best value for the hyperparameters. "
      ],
      "metadata": {
        "id": "QNyxQRW0inLX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the iris dataset\n",
        "data = load_iris()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the quantum kernel\n",
        "def swap_test_kernel(qc, q, theta):\n",
        "    qc.h(q[0])\n",
        "    qc.h(q[1])\n",
        "    qc.h(q[2])\n",
        "    qc.cswap(q[0], q[1], q[2])\n",
        "    qc.h(q[0])\n",
        "    qc.h(q[1])\n",
        "    qc.measure_all()\n",
        "\n",
        "num_qubits = 3\n",
        "theta = np.random.uniform(0, 2*np.pi, num_qubits)\n",
        "\n",
        "feature_map = ZFeatureMap(feature_dimension=2, reps=2)\n",
        "quantum_instance = Aer.get_backend('qasm_simulator')\n",
        "kernel = QuantumKernel(feature_map=feature_map, enforce_psd=True, batch_size=100, \n",
        "                       quantum_instance=quantum_instance, training_parameters=None, \n",
        "                       evaluate_duplicates='off_diagonal')\n",
        "\n",
        "# Train the QSVM \n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from qiskit_machine_learning.algorithms.classifiers import QSVC\n",
        "\n",
        "param_grid = {'C': [0.1, 0.5, 1, 10],\n",
        "              'gamma': [0.01, 0.1, 1],\n",
        "              'degree': [2, 3, 4]}\n",
        "\n",
        "qsvc = QSVC(quantum_kernel=kernel)\n",
        "clf = GridSearchCV(qsvc, param_grid, cv=5)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "print(\"Best parameters found: \", clf.best_params_)\n",
        "print(\"Best score: \", clf.best_score_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JTVg1i68hX_c",
        "outputId": "78591010-2175-4f67-bf47-f730e75ba659"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters found:  {'C': 1, 'degree': 3, 'gamma': 0.01}\n",
            "Best score:  0.9333333333333333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>\n",
        "<br>\n",
        "\n",
        "\n",
        "After finding the best hyperparameter values for my QSVC Implementation, I wanted to start thinking about reducing the number of qubits and depth, and see how it would affect the accuracy of this problem. When doing some research, I realized that we had taken a multi-class classification problem, and turned it into a binary classification problem. And because we did that, it should be possible to reduce the number of qubits from 3 to 2. And that is exactly what I do below. \n",
        "\n",
        "<br>\n",
        "\n",
        "I first changed the implementation of the Swap Test. From Ref#3, which uses a CNOT gate instead of a CSWAP gate. The idea is as follows:\n",
        "\n",
        "In the swap test, the CSWAP gate is used to entangle three qubits, where the first two qubits contain the state to be compared, and the third qubit acts as the control. The CSWAP gate flips the state of the third qubit if and only if the first two qubits are in the same state.\n",
        "\n",
        "We can perform a similar swap test with only two qubits, by replacing the CSWAP gate with a CNOT gate. In this case, we only need two qubits: one to hold the input state and the other to act as the control. The CNOT gate flips the second qubit (control qubit) if and only if the first qubit (target qubit) is in the state |1>. Thus, we can use the CNOT gate to achieve the same effect as the CSWAP gate in the swap test.  \n"
      ],
      "metadata": {
        "id": "gux26b5nfdLP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the iris dataset\n",
        "data = load_iris()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the quantum kernel\n",
        "def swap_test_kernel(qc, q, theta):\n",
        "    qc.h(q[0])\n",
        "    qc.cnot(q[0], q[1])\n",
        "    qc.h(q[0])\n",
        "    qc.measure_all()\n",
        "\n",
        "num_qubits = 2\n",
        "theta = np.random.uniform(0, 2*np.pi, num_qubits)\n",
        "\n",
        "from qiskit.circuit.library import ZFeatureMap\n",
        "from qiskit import Aer\n",
        "\n",
        "feature_map = ZFeatureMap(feature_dimension=2, reps=2)\n",
        "quantum_instance = Aer.get_backend('qasm_simulator')\n",
        "kernel = QuantumKernel(feature_map=feature_map, enforce_psd=True, batch_size=40, \n",
        "                       quantum_instance=quantum_instance, training_parameters=None, \n",
        "                       evaluate_duplicates='off_diagonal')\n",
        "\n",
        "# Train the QSVM using the one-vs-all approach\n",
        "qsvms = []\n",
        "for i in range(len(np.unique(y_train))):\n",
        "    # Prepare binary labels for the current class\n",
        "    y_train_binary = np.zeros(len(y_train))\n",
        "    y_train_binary[y_train == i] = 1\n",
        "    if np.sum(y_train_binary) == 0:\n",
        "        continue  # Skip if there are no samples for the current class\n",
        "        \n",
        "    # Train the QSVM for the current class\n",
        "    qc = QuantumCircuit(num_qubits)\n",
        "    swap_test_kernel(qc, [0,1,2], theta)\n",
        "    qsvc = QSVC(quantum_kernel=kernel, C=1, gamma=0.01, degree=3)\n",
        "    qsvc.fit(X_train, y_train_binary)\n",
        "    \n",
        "    qsvms.append(qsvc)\n",
        "\n",
        "# Test the QSVM\n",
        "y_pred = np.zeros((len(X_test), len(np.unique(y_train))))\n",
        "for i in range(len(X_test)):\n",
        "    for j in range(len(np.unique(y_train))):\n",
        "        qc = QuantumCircuit(num_qubits)\n",
        "        swap_test_kernel(qc, [0,1,2], theta)\n",
        "        kernel.quantum_circuit = qc\n",
        "        y_pred[i, j] = qsvms[j].predict(X_test[i:i+1,:])\n",
        "\n",
        "y_pred = np.argmax(y_pred, axis=1)\n",
        "\n",
        "# Evaluate the accuracy of the QSVM\n",
        "accuracy = sum([y_test[i]==y_pred[i] for i in range(len(y_test))])/len(y_test)\n",
        "print('Accuracy:', accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gFN__nraFolO",
        "outputId": "e696def4-b2f0-4dc1-eb08-26d48084ea4c"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9333333333333333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>\n",
        "\n",
        "As you can see here, I was able to reduce the number of qubits from n=3 to n=2, and also reduce the depth of the circuit from the original Swap Test Kernal implementation of 7 to this modified of 3. All while keeping an accuracy of 93%. "
      ],
      "metadata": {
        "id": "pvoYkn6bnlV5"
      }
    }
  ]
}